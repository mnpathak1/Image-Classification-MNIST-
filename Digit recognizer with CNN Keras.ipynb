{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After loading the dataset, this analysis is mainly divided into five parts:\n",
    "\n",
    "1. Quick EDA: check data shape, view null, check labels\n",
    "2. Data preparation: normalization, reshape, one-hot label representation, train-test split\n",
    "3. CNN: define model, optimizer, dynamic learning rate, data augmentation\n",
    "4. Evaluate model: model accuracy, loss, confusion matrix and error analysis\n",
    "5. Prediction and submission: apply model on test dataset\n",
    "\n",
    "At the end, I have compared different optimizers for classification to justify my selection of classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 0. Load libraries and dataet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. EDA\n",
    "\n",
    "Below are some quick exploration of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We have 784 pixel (28 x 28) columns and 1 label column in training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Test dataset does not have label column because we are going to predict it.\n",
    "\n",
    "Let us see the labels in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEFCAYAAAD5bXAgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15efb2932b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train dataset has 10 labels (digits from 0 to 9) and ther distribution are very similar.  \n",
    "Below are actual counts on each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Check for null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There is no missing values an we can safely proceed without data imputation or exclusion.\n",
    "\n",
    "# 2. Data preparation\n",
    "\n",
    "### Normalization\n",
    "\n",
    "We perform greyscale normalization to reduce the effect of illumination differences.  \n",
    "Moreover the CNN converg faster on [0..1] data than on [0..255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , chanal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)  # -1 suggests it is not defined and numpy will figure out\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train and test images (28 x 28) have been stock into pandas Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.  \n",
    "\n",
    "Keras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.\n",
    "\n",
    "### Label encoding: one-hot represenation of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Labels are 10 digits numbers from 0 to 9. We need to encode these lables to **one hot vectors** (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Split train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model.  We have 42000 training images of 10 balanced labels. Therefore, a random split of the train set doesn't cause some labels to be over represented in the validation set (may not be true for unbalanced data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 28, 28, 1)\n",
      "(4200, 28, 28, 1)\n",
      "(37800, 10)\n",
      "(4200, 10)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(Y_train))\n",
    "print(np.shape(Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15e9fd34160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD3CAYAAAA0cknjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15e9fc523c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[200][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. CNN\n",
    "\n",
    "#### Define CNN model\n",
    "\n",
    "###### Conv2D->relu -> Conv2D->relu  -> MaxPool2D -> Dropout -> Conv2D->relu -> Conv2D->relu  -> MaxPool2D -> Dropout -> Flatten -> Dense -> Dropout -> Dense -> Dropout -> Output\n",
    "\n",
    "In Keras API (with Tensorflow) backend, we add one layer at a time starting from the input layer.\n",
    "\n",
    "\n",
    "The **first layer is a Conv2D convolution layer** with 32 filters each with kernel size 5x5. Each filter transforms a part of the image (defined by the kernel size) using the kernel filter. The kernel filter matrix is applied on the whole image. Filters identify different features in the image.  \n",
    "We are using **same padding** that results in padding the input such that the output has the same length as the original input. Padding is important for the edges of the images.  \n",
    "**Relu** is the rectifier (activation function max(0,x). The rectifier activation function is used to add non linearity to the network.  \n",
    "The **pooling (MaxPool2D)** layer acts as a downsampling filter. It looks at the 2 neighboring pixels (we are using 2x2 pull size here) and picks the maximal value. These are used to reduce computational cost, and to some extent also reduce overfitting. More the pooling dimension is high, more the downsampling is important.  \n",
    "**Dropout** is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training sample. This drops randomly a propotion of the network and forces the network to learn features in a distributed way. This technique also improves generalization and reduces the overfitting. \n",
    "**The Flatten layer** is use to convert the final feature maps into a one single 1D vector. This flattening step is needed so that you can make use of fully connected layers after some convolutional/maxpool layers. It combines all the found local features of the previous convolutional layers.  \n",
    "In the end I have used the features in **two fully-connected** (Dense) layers. Then I add the the last layer as the output layer  with **softmax activation** (Dense(10,activation=\"softmax\")) that gives the probability of each 10 labels in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set the Optimizer and annealer\n",
    "\n",
    "Since the model is set up, now we can **set up the accuracy i.e. score, loss function and Optimizer**.  \n",
    "**Loss function** is the error rate between the observed labels and the predicted labels. For our multiple class classification (>2 class), we use [**categorical_crossentropy**](https://keras.io/losses/).  \n",
    "The **Optimizer** minimizes loss with backpropagation. It iteratively improves the model parameters (filter kernel  values, weights and biases at each layer and each neuron). I am using [**Adam Optimization**](https://keras.io/optimizers/) that takes into account both momentum and RMSProp in gradient descent. Below are the arguments in Adam from Keras doc (I am using the default values to start with):   \n",
    "\n",
    "lr: float >= 0. Learning rate.  \n",
    "beta_1: float, 0 < beta < 1. Generally close to 1.  \n",
    "beta_2: float, 0 < beta < 1. Generally close to 1.  \n",
    "epsilon: float >= 0. Fuzz factor. If None, defaults to K.epsilon().  \n",
    "decay: float >= 0. Learning rate decay over each update.  \n",
    "amsgrad: boolean. Whether to apply the AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and Beyond\".  \n",
    "\n",
    "**Accuracy** is metric function that evaluates the performance the model. Loss is expected to go lower as accuracy goes higher after each iteration (or epoch). The results from the metric evaluation are not used when training the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "Adamopti = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = Adamopti , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Learning rate and model convergence\n",
    "\n",
    "The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima. Learning rate should be sufficiently small to reach the global minimum in cost optimization however, it can be computationally costly.   \n",
    "To keep the advantage of the fast computation time with a high LR, I decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).  \n",
    "In ReduceLROnPlateau function from Keras.callbacks, I choose to reduce the LR by half if the accuracy is not improved after 3 epochs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs = 1 # Turn epochs to higher number (~25 or higher) for better accuracy\n",
    "batch_size = 86 # Can be other number as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Augmentation\n",
    "\n",
    "In image data, we have the leverage to increase variation in training sample by **data augmentation that improves model accuracy**. \n",
    "This alters the training data in ways that change the array representation while keeping the label the same. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.  \n",
    "\n",
    "By applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.  \n",
    "\n",
    "* Without data augmentation, I  get validation accuracy of 97.95%.\n",
    "* With data augmentation, I get validation accuracy of 98.40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 426s - loss: 0.3660 - acc: 0.8791 - val_loss: 0.0637 - val_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "# Without data augmentation i obtained an accuracy of 0.98114\n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For the data augmentation, I choosed to :\n",
    "\n",
    "* Randomly rotate some training images by 10 degrees\n",
    "* Randomly Zoom by 10% some training images\n",
    "* Randomly shift images horizontally by 10% of the width\n",
    "* Randomly shift images vertically by 10% of the height\n",
    "\n",
    "I did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\n",
    "\n",
    "Once our model is ready, we fit the training dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 423s - loss: 0.5857 - acc: 0.8062 - val_loss: 0.0828 - val_acc: 0.9762\n",
      "Epoch 2/25\n",
      " - 419s - loss: 0.1742 - acc: 0.9512 - val_loss: 0.0506 - val_acc: 0.9864\n",
      "Epoch 3/25\n",
      " - 417s - loss: 0.1311 - acc: 0.9644 - val_loss: 0.0676 - val_acc: 0.9793\n",
      "Epoch 4/25\n",
      " - 405s - loss: 0.1064 - acc: 0.9703 - val_loss: 0.0321 - val_acc: 0.9914\n",
      "Epoch 5/25\n",
      " - 384s - loss: 0.0947 - acc: 0.9738 - val_loss: 0.0379 - val_acc: 0.9879\n",
      "Epoch 6/25\n",
      " - 379s - loss: 0.0811 - acc: 0.9774 - val_loss: 0.0436 - val_acc: 0.9902\n",
      "Epoch 7/25\n",
      " - 380s - loss: 0.0770 - acc: 0.9783 - val_loss: 0.0269 - val_acc: 0.9933\n",
      "Epoch 8/25\n",
      " - 382s - loss: 0.0752 - acc: 0.9795 - val_loss: 0.0301 - val_acc: 0.9917\n",
      "Epoch 9/25\n",
      " - 383s - loss: 0.0696 - acc: 0.9809 - val_loss: 0.0286 - val_acc: 0.9926\n",
      "Epoch 10/25\n",
      " - 380s - loss: 0.0661 - acc: 0.9820 - val_loss: 0.0262 - val_acc: 0.9931\n",
      "Epoch 11/25\n",
      " - 380s - loss: 0.0651 - acc: 0.9821 - val_loss: 0.0224 - val_acc: 0.9950\n",
      "Epoch 12/25\n",
      " - 383s - loss: 0.0615 - acc: 0.9828 - val_loss: 0.0266 - val_acc: 0.9924\n",
      "Epoch 13/25\n",
      " - 380s - loss: 0.0578 - acc: 0.9835 - val_loss: 0.0156 - val_acc: 0.9950\n",
      "Epoch 14/25\n",
      " - 379s - loss: 0.0578 - acc: 0.9840 - val_loss: 0.0177 - val_acc: 0.9950\n",
      "Epoch 15/25\n",
      " - 379s - loss: 0.0541 - acc: 0.9848 - val_loss: 0.0222 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 16/25\n",
      " - 380s - loss: 0.0439 - acc: 0.9879 - val_loss: 0.0195 - val_acc: 0.9952\n",
      "Epoch 17/25\n",
      " - 377s - loss: 0.0358 - acc: 0.9897 - val_loss: 0.0240 - val_acc: 0.9957\n",
      "Epoch 18/25\n",
      " - 385s - loss: 0.0382 - acc: 0.9896 - val_loss: 0.0208 - val_acc: 0.9952\n",
      "Epoch 19/25\n",
      " - 376s - loss: 0.0352 - acc: 0.9903 - val_loss: 0.0233 - val_acc: 0.9955\n",
      "Epoch 20/25\n",
      " - 376s - loss: 0.0336 - acc: 0.9902 - val_loss: 0.0189 - val_acc: 0.9957\n",
      "Epoch 21/25\n",
      " - 374s - loss: 0.0341 - acc: 0.9897 - val_loss: 0.0231 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 22/25\n",
      " - 374s - loss: 0.0303 - acc: 0.9918 - val_loss: 0.0186 - val_acc: 0.9960\n",
      "Epoch 23/25\n",
      " - 24363s - loss: 0.0274 - acc: 0.9930 - val_loss: 0.0197 - val_acc: 0.9955\n",
      "Epoch 24/25\n",
      " - 410s - loss: 0.0271 - acc: 0.9924 - val_loss: 0.0213 - val_acc: 0.9950\n",
      "Epoch 25/25\n",
      " - 408s - loss: 0.0269 - acc: 0.9928 - val_loss: 0.0198 - val_acc: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Evaluate model\n",
    "### Training and validation curves vs. epoch\n",
    "\n",
    "Since only one epoch is used due to computation limitation, following is not going to print.  \n",
    "As I noticed, the validation accuracy is greater than the training accuracy almost every time during the training. That means that our model is not overfitting the training set.  \n",
    "The model is well trained!  \n",
    "\n",
    "To further improve the model, we definitely need to use more number of epochs.\n",
    "With 25 epochs (ran it overnight), I got 99.6% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD5CAYAAADY+KXfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF0IIHyKhLoQQPuT/A6I0MZWXV3VZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23c1e3f7b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation vs. epochs\n",
    "# Since I have just 1 epoch, the curves are empty\n",
    "#fig, ax = plt.subplots(2,1)\n",
    "#ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "#ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "#legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "#ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "#ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "#legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "Confusion matrix helps us to understand model error or misclassification.  \n",
    "I don't see any direct way to get the confusion matrix from Keras and therefore, the following function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAEiCAYAAABqcBCCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne3kj595xx84AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23c3cdf7a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we can see that our CNN performs very well on all digits with few misclassification errors.  \n",
    "It seems that our CNN has some little troubles with the 9, 8 and so on digits, they are misclassified as 4, 7, 1 etc. For example, sometime it is very difficult to catch the difference between 4 and 9 when curves are smooth and so on.  \n",
    "\n",
    "### Error analysis\n",
    "\n",
    "Let's investigate for errors.\n",
    "\n",
    "I want to see the most important errors . For that purpose i need to get the difference between the probabilities of real value and the predicted ones in the results.\n",
    "\n",
    "Errors are difference between predicted labels and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "errors = (Y_pred_classes - Y_true != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next we define the following function to display some errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then define and evaluate the following quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Show the top 6 errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAERCAYAAAC0FCalAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23c3d278a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We see that these errors are also can easily be made by humans. These digits are written almost imcomplete.\n",
    "\n",
    "# 5. Submission\n",
    "\n",
    "Following is the submission on the test datatset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the index with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model comparison (Additional)\n",
    "\n",
    "These models are based on Gradient Descent (GD) approach and estimation of loss with backpropagation (some details in references). \n",
    "\n",
    "## 1. SGD: Stochastic Gradient descent\n",
    "\n",
    "In SGD, we update the weights based on each training example, not the batch as a whole as done in GD.   \n",
    "That is, weights are updated elementwise as wj:=wj+dwj instead of as a whole as W:=W+dW.  \n",
    "SGD is computationally less demanding than GD since we don't have to run through the whole training set to update the weights.  \n",
    "Although SGD minimizes loss faster, it is noisier and it oscillates around the the minimum giving some variation in accuracy and loss run to  run.  \n",
    "\n",
    "In Keras implementation of SGD, I am using LR of 0.01. Keras gives option to use momentum and decay of LR in SGD but I am not using those (set to 0). Momentum enables faster gradient descent.  \n",
    "\"nesterov\" gives option to use mementum in a different way. It is set to False. Use of momentum helps to to achive faster convergence of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 387s - loss: 2.2419 - acc: 0.1742 - val_loss: 1.6659 - val_acc: 0.6410\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "modelsgd = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(modelsgd.history.keys())\n",
    "sgdacc= modelsgd.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. RMSProp\n",
    "\n",
    "RMSProp is root mean squared propagation. In this algorithm, we divide the learning rate for a weight by a running average of\tthe magnitudes\tof\trecent\tgradients for that weight. This helps in faster gradient descent and it is more accurate than SGD. \n",
    "RMSProp was proposed by Geoffrey Hinton.\n",
    "\n",
    "In Keras implementation of RMSProp, I am using LR of 0.01 and rest of the values as default as recommended.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 377s - loss: 0.3414 - acc: 0.8957 - val_loss: 0.0857 - val_acc: 0.9726\n"
     ]
    }
   ],
   "source": [
    "rmsprop = optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "modelrmsprop = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rmspropacc = modelrmsprop.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that we already have much better accuracy with RMSProp compared to SGD.\n",
    "\n",
    "## 3. Adagrad\n",
    "\n",
    "In Adagrad method, we have adaptive learning rate i.e. learning rate is adjusted based on the learning in previous step. We have different learning rate for different parameters at every step of the neural net. Because of learning rate is updated with 1/sqrt(grad^2+epsilon) in Adagrad, high gradient learning rate gets reduced and small gradient lerrning rate is increased.  Adagrad helps in learning from sparse (less frequent) data.  \n",
    "\n",
    "In Keras implementation of Adagrad, I am using learning rate of 0.01 to start with without any decay (decay=0) for learning rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 388s - loss: 0.2708 - acc: 0.9578 - val_loss: 0.0512 - val_acc: 0.9845\n"
     ]
    }
   ],
   "source": [
    "adagrad = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "modeladagrad = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adagradacc = modeladagrad.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Adadelta\n",
    "\n",
    "Adadelta is an extension of Adagrad. Adadelta addresses the monotonically decreasing LR in Adagrad (accumulated thourgh squared gradient in learning rate update in the denominator in Adagrad). It scales the learning rate within certain window (with the rho parameter) together with having a momentum (faster convergence) approach.\n",
    "\n",
    "Default LR is not quite important in Adadelta. In Keras implementation, I have kept it as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 378s - loss: 0.0748 - acc: 0.9786 - val_loss: 0.0464 - val_acc: 0.9876\n"
     ]
    }
   ],
   "source": [
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "modeladadelta = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adadeltaacc = modeladadelta.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Adam\n",
    "\n",
    "Adam (Adaptive Moment Estimation) is basically RMSProp with momentum. In practice Adam is currently recommended as the default algorithm to use, and often works slightly better than RMSProp. An alternative to Adam can be SGD+Nesterov Momentum. Adam starts with zero bias. More details about Adam with bias correction and can be found in the references at the end. \n",
    "\n",
    "Adam update rules with bias correction are as follow. Here dx is the gradient, beta1 and beta2 are the parameters introduced in the algorithms (they are close to 1), m is smooth version of gradient, v is the defined momentum and t as number of iterations:\n",
    "\n",
    "m = beta1 x m + (1-beta1) x dx  \n",
    "mt = m / (1-beta1^t)  \n",
    "v = beta2 x v + (1-beta2) x (dx^2)  \n",
    "vt = v / (1-beta2^t)    \n",
    "x += - learning_rate x mt / (np.sqrt(vt) + eps)  \n",
    "\n",
    "In Keras implementation of Adam, I am using LR of 0.01 and other values at default as recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 432s - loss: 0.0694 - acc: 0.9804 - val_loss: 0.0476 - val_acc: 0.9860\n"
     ]
    }
   ],
   "source": [
    "adam = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modeladam = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adamacc = modeladam.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 6. Adamax\n",
    "\n",
    "Adamax is generalized version of Adam. In Adam we have l1 and l2 norms in momnetum updates. In Adamax, it is extended to infinite norm (i.e. max). it provides stable convergence of gradient descent.   \n",
    "\n",
    "Adamax parameters are similar to Adam in Keras implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 386s - loss: 0.0459 - acc: 0.9866 - val_loss: 0.0379 - val_acc: 0.9907\n"
     ]
    }
   ],
   "source": [
    "adamax = optimizers.Adamax(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
    "modeladamax = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adamaxacc = modeladamax.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7. Nadam\n",
    "\n",
    "As stated earlier, Adam is RMSProp with momnetum. Nadam is basically Adam with momentum specified as Nesterov momentum. Then parameter update rules change accordingly.  \n",
    "Keras implementation in Nadam is similar to Adam.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 378s - loss: 0.0750 - acc: 0.9783 - val_loss: 0.0464 - val_acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "nadam = optimizers.Nadam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "modelnadam = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nadamacc = modelnadam.history['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the accuracies of these models all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adamax</th>\n",
       "      <td>0.990714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nadam</th>\n",
       "      <td>0.988571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adadelta</th>\n",
       "      <td>0.987619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adam</th>\n",
       "      <td>0.985952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adagrad</th>\n",
       "      <td>0.984524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSProp</th>\n",
       "      <td>0.972619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD</th>\n",
       "      <td>0.640952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy\n",
       "Adamax    0.990714\n",
       "Nadam     0.988571\n",
       "Adadelta  0.987619\n",
       "Adam      0.985952\n",
       "Adagrad   0.984524\n",
       "RMSProp   0.972619\n",
       "SGD       0.640952"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = []\n",
    "accuracy.append(sgdacc)\n",
    "accuracy.append(rmspropacc)\n",
    "accuracy.append(adagradacc)\n",
    "accuracy.append(adadeltaacc)\n",
    "accuracy.append(adamacc)\n",
    "accuracy.append(adamaxacc)\n",
    "accuracy.append(nadamacc)\n",
    "\n",
    "Optimizers = ['SGD', 'RMSProp', 'Adagrad','Adadelta','Adam','Adamax','Nadam']\n",
    "\n",
    "models_dataframe=pd.DataFrame(accuracy, index=Optimizers) \n",
    "models_dataframe.columns=['Accuracy']\n",
    "models_dataframe\n",
    "models_dataframe.sort_values(['Accuracy'], ascending=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Adamax is showing the highest accuracy. However, I would say that except SGD, all other models are quite close. Also, these accuracies are just with one epoch.\n",
    "\n",
    "## What optimizer to pick?\n",
    "\n",
    "The most basic optimizers are gradient descent (GD) and then stochastic gradient descent (SGD). Later optimizers all perform better than SGD in general. In sparse data, we can use adaptive learning rate method such as Adagrad or Adadelta. Then RMSProp is an extension of Adagrad that accounts for its monotonically vanishing learning rate. Adam adds momentum to RMSProp and finally bias is corrected in Adam. In that way, Adam is found to  be the most updated and overall best choice. In general, Adadelta, RMSProp and Adam should perform very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Below codes compare all the different classifiers together. But it takes a while to run.\n",
    "#loss=[]\n",
    "#accuracy=[]\n",
    "#Optimizers = ['sgd', 'rmsprop', 'Adagrad','Adadelta','Adam','Adamax','Nadam']\n",
    "\n",
    "#for i in Optimizers:\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer=i, metrics=['accuracy'])\n",
    "#    model.fit(X_train, Y_train, batch_size = 86, epochs = 1)\n",
    "#    score, acc = model.evaluate(X_val, Y_val)\n",
    "#    loss.append(score)\n",
    "#    accuracy.append(acc)\n",
    "#    \n",
    "#cv_models_dataframe=pd.DataFrame(accuracy, index=Optimizers) \n",
    "#cv_models_dataframe.columns=['Accuracy']\n",
    "#cv_models_dataframe\n",
    "#cv_models_dataframe.sort_values(['Accuracy'], ascending=[0])\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## Reference\n",
    "\n",
    "* I took direct help from [Yassine G.'s very popular kernel](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6) on this analysis of this digit recognizer dataset (Thank you!) and some help from Keras documentation. I used slightly different network with Adam optimizer instead of RMSProp. The confusion matrix and error Analysis I learned from his kernel is really insightful and helpful to me.\n",
    "* Links to material I went through to understand different Neural Network algorithms based on Gradient Descent Optimization  \n",
    "  * Geoffrey Honton's [notes](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
    "  * Stanford CS231 [notes and discussion](http://cs231n.github.io/neural-networks-3) on the algorithms\n",
    "  * [Blog](http://ruder.io/optimizing-gradient-descent/index.html) by Sebastian R.\n",
    "  * A good read about [SGD](https://www.quora.com/Whats-the-difference-between-gradient-descent-and-stochastic-gradient-descent) in Quora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
